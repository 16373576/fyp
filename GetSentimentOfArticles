import json
import os
from collections import Counter

import numpy as np
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer


def main():
    # define variables
    analyzer = SentimentIntensityAnalyzer()
    dictKeys = []
    stringKeys = ""

    #  a subset of all sources for the articles in the NELA2017 dataset
    sources = ["AP", "BBC", "PBS", "Salon", "Slate", "The New York Times", "BuzzFeed", "Drudge Report", "Faking News",
               "RedState", "The Gateway Pundit", "The Huffington Post"]

    # second subset sources used to determine if the results so far are dependent on the current sources being used
    # sources = ["CNN", "MotherJones", "NPR", "PBS", "The Hill", "Vox", "Addicting Info", "New York Daily News", "Prntly",
    #            "The D.C. Clothesline", "The Duran", "Yahoo News"]

    for s in sources:
        if not os.path.isfile("C:/Users/caire/Desktop/OutputData/OutputWordSentiment/" + s + ".txt"):
            with open("C:/Users/caire/Desktop/OutputData/OutputWordsArticles/" + s + ".txt") as file:
                print("analysing content in " + s + " articles")
                for cnt, line in enumerate(file):
                    line = line.replace("Counter(", "").replace(")", "")
                    lineDict = eval(line)
                    dictKeys = lineDict.keys()
                    for word in dictKeys:
                        if not stringKeys:
                            stringKeys = word
                        else:
                            stringKeys = stringKeys + " " + word
                    scores = analyzer.polarity_scores(stringKeys)
                    print(scores)
                    stringKeys = ""
                    with open("C:/Users/caire/Desktop/OutputData/OutputWordSentiment/" + s + ".txt",
                              'a') as newFile:
                        newFile.write(str(scores.get("compound")) + "\n")


main()
